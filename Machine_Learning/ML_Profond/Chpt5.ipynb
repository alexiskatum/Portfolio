{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f61852bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/9e/b8/ed5f794359d05cd0bffb894c6418da87b93016ee17b669d55c45d1bd5d5b/tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.13.0 from https://files.pythonhosted.org/packages/2f/2f/3c84f675931ce3bcbc7e23acbba1e5d7f05ce769adab48322de57a9f5928/tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ---------------------------------------- 0.0/126.5 kB ? eta -:--:--\n",
      "     ------------------ -------------------- 61.4/126.5 kB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 122.9/126.5 kB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 126.5/126.5 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.1.21 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 51.2/57.5 kB 2.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 51.2/57.5 kB 2.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 57.5/57.5 kB 433.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/02/8c/dc970bc00867fe290e8c8a7befa1635af716a9ebdfe3fb9dce0ca4b522ce/libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "     ------------------------------------- -- 61.4/65.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.5/65.5 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/14/ff/10f746c03212fe48576b2c0f5ada73c3400b6d90f769728c4f07656d8b27/protobuf-4.24.2-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.24.2-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/8d/58/ede228c07bdf3780c5332660c89f3c7a37fe8bfb9bd73a97ad2614420bd4/grpcio-1.57.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.57.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/5.6 MB 5.5 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.3/5.6 MB 4.2 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.5/5.6 MB 4.1 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.9/5.6 MB 5.2 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 1.3/5.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 1.8/5.6 MB 6.6 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 2.3/5.6 MB 7.3 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 2.8/5.6 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 3.4/5.6 MB 8.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 3.7/5.6 MB 8.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 4.7/5.6 MB 9.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.2/5.6 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.6/5.6 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.6/5.6 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.6/5.6 MB 8.7 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.1/1.5 MB 3.6 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 0.4/1.5 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.7/1.5 MB 5.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/9c/8d/bff87fc722553a5691d8514da5523c23547f3894189ba03b57592e37bdc2/google_auth-2.22.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/da/61/6e9ff8258422d287eec718872fb71e05324356722ab658c8afda25f51539/tensorboard_data_server-0.7.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "     ----------------------- --------------- 92.2/151.7 kB 5.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- -- 143.4/151.7 kB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 151.7/151.7 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.13.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Downloading tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl (276.6 MB)\n",
      "   ---------------------------------------- 0.0/276.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/276.6 MB 5.9 MB/s eta 0:00:47\n",
      "   ---------------------------------------- 0.6/276.6 MB 7.2 MB/s eta 0:00:39\n",
      "   ---------------------------------------- 0.9/276.6 MB 7.5 MB/s eta 0:00:37\n",
      "   ---------------------------------------- 1.5/276.6 MB 8.6 MB/s eta 0:00:32\n",
      "   ---------------------------------------- 2.0/276.6 MB 9.0 MB/s eta 0:00:31\n",
      "   ---------------------------------------- 2.7/276.6 MB 10.0 MB/s eta 0:00:28\n",
      "   ---------------------------------------- 3.3/276.6 MB 10.6 MB/s eta 0:00:26\n",
      "    --------------------------------------- 4.0/276.6 MB 11.1 MB/s eta 0:00:25\n",
      "    --------------------------------------- 4.7/276.6 MB 11.6 MB/s eta 0:00:24\n",
      "    --------------------------------------- 5.5/276.6 MB 12.1 MB/s eta 0:00:23\n",
      "    --------------------------------------- 6.5/276.6 MB 12.9 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 7.2/276.6 MB 13.1 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 8.2/276.6 MB 13.7 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 9.1/276.6 MB 14.2 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 10.0/276.6 MB 14.5 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 10.9/276.6 MB 16.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 11.9/276.6 MB 17.2 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 12.7/276.6 MB 17.7 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 13.7/276.6 MB 18.7 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 14.6/276.6 MB 19.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 15.5/276.6 MB 19.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 16.4/276.6 MB 19.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 17.1/276.6 MB 19.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 17.7/276.6 MB 19.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 18.4/276.6 MB 18.7 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 19.5/276.6 MB 19.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 20.3/276.6 MB 18.7 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 21.0/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 21.0/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 21.0/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 21.0/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 24.9/276.6 MB 18.2 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 25.4/276.6 MB 17.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 25.6/276.6 MB 16.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 25.9/276.6 MB 16.0 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 26.2/276.6 MB 15.2 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 27.2/276.6 MB 15.6 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 27.8/276.6 MB 15.2 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 28.4/276.6 MB 15.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 29.2/276.6 MB 15.2 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 30.0/276.6 MB 14.9 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 30.5/276.6 MB 14.6 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 31.3/276.6 MB 19.3 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 32.1/276.6 MB 17.7 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 32.6/276.6 MB 16.8 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 33.0/276.6 MB 16.0 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 34.1/276.6 MB 14.6 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 34.6/276.6 MB 13.6 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 35.6/276.6 MB 13.4 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 36.0/276.6 MB 14.2 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 37.1/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 37.1/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 37.1/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 37.1/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 37.3/276.6 MB 12.4 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 37.3/276.6 MB 12.4 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 37.3/276.6 MB 12.4 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 37.5/276.6 MB 10.9 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 37.5/276.6 MB 10.9 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 37.7/276.6 MB 9.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 37.8/276.6 MB 9.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 37.8/276.6 MB 9.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 37.8/276.6 MB 9.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 37.8/276.6 MB 9.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 37.8/276.6 MB 9.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 37.8/276.6 MB 9.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 37.8/276.6 MB 9.6 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 38.7/276.6 MB 7.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 38.7/276.6 MB 7.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 38.7/276.6 MB 7.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 38.7/276.6 MB 7.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 38.7/276.6 MB 7.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 38.7/276.6 MB 7.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 38.7/276.6 MB 7.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 38.7/276.6 MB 7.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 39.2/276.6 MB 6.1 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 39.2/276.6 MB 6.1 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 39.2/276.6 MB 6.1 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 39.2/276.6 MB 6.1 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 39.4/276.6 MB 5.5 MB/s eta 0:00:43\n",
      "   ----- ---------------------------------- 39.4/276.6 MB 5.5 MB/s eta 0:00:43\n",
      "   ----- ---------------------------------- 39.4/276.6 MB 5.5 MB/s eta 0:00:43\n",
      "   ----- ---------------------------------- 39.4/276.6 MB 5.5 MB/s eta 0:00:43\n",
      "   ----- ---------------------------------- 39.4/276.6 MB 5.5 MB/s eta 0:00:43\n",
      "   ----- ---------------------------------- 39.4/276.6 MB 5.5 MB/s eta 0:00:43\n",
      "   ----- ---------------------------------- 39.4/276.6 MB 5.5 MB/s eta 0:00:43\n",
      "   ----- ---------------------------------- 39.4/276.6 MB 5.5 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 43.4/276.6 MB 5.2 MB/s eta 0:00:45\n",
      "   ------ --------------------------------- 46.1/276.6 MB 5.7 MB/s eta 0:00:41\n",
      "   ------ --------------------------------- 46.1/276.6 MB 5.7 MB/s eta 0:00:41\n",
      "   ------ --------------------------------- 46.7/276.6 MB 5.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 47.1/276.6 MB 5.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 47.1/276.6 MB 5.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 47.1/276.6 MB 5.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 47.1/276.6 MB 5.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 47.1/276.6 MB 5.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 47.1/276.6 MB 5.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 47.1/276.6 MB 5.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 47.3/276.6 MB 4.5 MB/s eta 0:00:51\n",
      "   ------ --------------------------------- 47.3/276.6 MB 4.5 MB/s eta 0:00:51\n",
      "   ------ --------------------------------- 47.3/276.6 MB 4.5 MB/s eta 0:00:51\n",
      "   ------ --------------------------------- 47.3/276.6 MB 4.3 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 48.4/276.6 MB 6.3 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 48.4/276.6 MB 6.3 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 48.4/276.6 MB 6.3 MB/s eta 0:00:37\n",
      "   ------- -------------------------------- 48.7/276.6 MB 5.8 MB/s eta 0:00:40\n",
      "   ------- -------------------------------- 49.3/276.6 MB 7.1 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 49.3/276.6 MB 7.1 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 49.3/276.6 MB 7.1 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 49.8/276.6 MB 9.9 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 50.3/276.6 MB 9.8 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 50.3/276.6 MB 9.8 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 50.3/276.6 MB 9.8 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 51.0/276.6 MB 8.4 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 51.2/276.6 MB 8.3 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 51.2/276.6 MB 8.3 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 51.2/276.6 MB 8.3 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 52.2/276.6 MB 7.3 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 52.4/276.6 MB 7.0 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 52.7/276.6 MB 6.9 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 52.9/276.6 MB 6.7 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 53.4/276.6 MB 6.5 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 53.7/276.6 MB 6.3 MB/s eta 0:00:36\n",
      "   ------- -------------------------------- 54.1/276.6 MB 6.1 MB/s eta 0:00:37\n",
      "   ------- -------------------------------- 54.5/276.6 MB 6.0 MB/s eta 0:00:38\n",
      "   ------- -------------------------------- 54.9/276.6 MB 5.8 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 55.3/276.6 MB 5.6 MB/s eta 0:00:40\n",
      "   -------- ------------------------------- 55.8/276.6 MB 5.5 MB/s eta 0:00:40\n",
      "   -------- ------------------------------- 56.3/276.6 MB 5.4 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 56.6/276.6 MB 5.6 MB/s eta 0:00:40\n",
      "   -------- ------------------------------- 57.4/276.6 MB 6.8 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 57.9/276.6 MB 7.4 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 58.6/276.6 MB 7.3 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 59.3/276.6 MB 7.9 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 59.8/276.6 MB 8.7 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 60.4/276.6 MB 8.6 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 61.2/276.6 MB 9.5 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 62.0/276.6 MB 10.7 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 62.8/276.6 MB 11.3 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 63.6/276.6 MB 12.1 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 64.3/276.6 MB 12.8 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 65.0/276.6 MB 13.6 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 65.8/276.6 MB 14.2 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 66.6/276.6 MB 14.9 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 67.4/276.6 MB 15.2 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 68.0/276.6 MB 15.2 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 68.9/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 69.7/276.6 MB 16.0 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 70.4/276.6 MB 16.0 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 70.8/276.6 MB 16.0 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 71.6/276.6 MB 16.0 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 72.0/276.6 MB 16.0 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 72.9/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 73.8/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 74.3/276.6 MB 15.6 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 74.8/276.6 MB 15.2 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 75.5/276.6 MB 15.2 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 76.1/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 77.0/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 77.8/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 78.5/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 79.3/276.6 MB 15.2 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 80.2/276.6 MB 15.2 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 81.1/276.6 MB 16.4 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 81.7/276.6 MB 15.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 82.4/276.6 MB 16.0 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 83.2/276.6 MB 16.0 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 84.0/276.6 MB 15.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 84.4/276.6 MB 16.0 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 85.4/276.6 MB 16.4 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 85.8/276.6 MB 16.0 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 86.6/276.6 MB 16.0 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 87.4/276.6 MB 16.0 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 88.3/276.6 MB 16.4 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 89.1/276.6 MB 16.4 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 89.6/276.6 MB 16.0 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 90.6/276.6 MB 16.0 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 91.1/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 91.8/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 92.6/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 93.4/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 94.2/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 94.9/276.6 MB 16.0 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 95.7/276.6 MB 16.8 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 96.0/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 96.8/276.6 MB 16.0 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 97.8/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 98.3/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 99.1/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 99.9/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 100.6/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 101.4/276.6 MB 16.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 102.2/276.6 MB 16.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 103.0/276.6 MB 16.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 103.9/276.6 MB 16.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 104.5/276.6 MB 16.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 105.2/276.6 MB 16.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 105.7/276.6 MB 15.6 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 106.6/276.6 MB 16.0 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 107.4/276.6 MB 16.4 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 108.2/276.6 MB 16.0 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 108.6/276.6 MB 16.0 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 109.4/276.6 MB 16.4 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 109.8/276.6 MB 15.2 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 110.4/276.6 MB 15.2 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 111.0/276.6 MB 14.6 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 111.9/276.6 MB 14.9 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 112.7/276.6 MB 14.6 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 113.6/276.6 MB 14.9 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 114.3/276.6 MB 14.9 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 115.2/276.6 MB 14.9 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 116.0/276.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 116.8/276.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 117.5/276.6 MB 15.2 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 118.2/276.6 MB 15.2 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 118.9/276.6 MB 15.2 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 119.6/276.6 MB 15.2 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 120.2/276.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 120.9/276.6 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 121.4/276.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 121.8/276.6 MB 14.9 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 122.4/276.6 MB 14.9 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 122.9/276.6 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 123.6/276.6 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 124.4/276.6 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 125.1/276.6 MB 13.9 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 125.9/276.6 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 126.7/276.6 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 127.4/276.6 MB 14.2 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 128.4/276.6 MB 14.9 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 128.9/276.6 MB 14.5 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 129.6/276.6 MB 14.6 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 130.4/276.6 MB 14.9 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 131.3/276.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 131.9/276.6 MB 15.2 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 132.3/276.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 133.1/276.6 MB 16.0 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 133.7/276.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 134.7/276.6 MB 16.0 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 134.9/276.6 MB 14.9 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 135.1/276.6 MB 14.2 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 136.3/276.6 MB 14.9 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 137.1/276.6 MB 14.9 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 138.0/276.6 MB 14.5 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 138.8/276.6 MB 14.9 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 139.6/276.6 MB 15.2 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 140.8/276.6 MB 16.0 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 141.9/276.6 MB 16.4 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 142.3/276.6 MB 16.0 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 143.6/276.6 MB 17.2 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 144.5/276.6 MB 18.2 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 145.5/276.6 MB 20.5 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 146.6/276.6 MB 20.5 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 147.4/276.6 MB 20.5 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 148.7/276.6 MB 21.1 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 149.3/276.6 MB 20.5 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 150.2/276.6 MB 20.5 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 151.0/276.6 MB 19.9 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 151.9/276.6 MB 19.8 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 152.8/276.6 MB 20.5 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 153.6/276.6 MB 19.8 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 154.7/276.6 MB 19.8 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 155.5/276.6 MB 19.8 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 156.4/276.6 MB 19.3 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 157.4/276.6 MB 19.3 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 158.2/276.6 MB 19.3 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 158.7/276.6 MB 18.2 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 159.8/276.6 MB 19.3 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 160.5/276.6 MB 18.2 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 161.4/276.6 MB 18.7 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 162.4/276.6 MB 18.7 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 163.2/276.6 MB 18.7 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 163.8/276.6 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 164.8/276.6 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 165.4/276.6 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 166.3/276.6 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 167.0/276.6 MB 17.2 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 167.5/276.6 MB 16.4 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 168.4/276.6 MB 16.8 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 169.2/276.6 MB 17.3 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 170.0/276.6 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 170.9/276.6 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 171.7/276.6 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 172.6/276.6 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 173.4/276.6 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 173.9/276.6 MB 16.4 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 174.0/276.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 174.1/276.6 MB 14.6 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 175.1/276.6 MB 14.6 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 176.0/276.6 MB 14.9 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 176.8/276.6 MB 15.2 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 177.6/276.6 MB 16.0 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 178.4/276.6 MB 15.2 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 179.4/276.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 180.2/276.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 181.1/276.6 MB 16.0 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 182.0/276.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 183.0/276.6 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 183.8/276.6 MB 16.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 184.6/276.6 MB 18.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 185.5/276.6 MB 18.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 186.0/276.6 MB 18.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 186.6/276.6 MB 17.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 187.3/276.6 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 188.2/276.6 MB 17.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 189.1/276.6 MB 17.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 190.0/276.6 MB 17.2 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 190.7/276.6 MB 16.8 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 191.3/276.6 MB 16.4 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 192.2/276.6 MB 16.8 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 192.9/276.6 MB 16.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 193.7/276.6 MB 16.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 194.5/276.6 MB 16.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 195.2/276.6 MB 16.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 196.1/276.6 MB 16.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 196.8/276.6 MB 16.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 197.5/276.6 MB 16.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 198.2/276.6 MB 16.4 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 199.0/276.6 MB 16.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 199.8/276.6 MB 16.4 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 200.2/276.6 MB 16.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 200.9/276.6 MB 16.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 201.3/276.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 202.3/276.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 202.7/276.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 203.4/276.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 204.3/276.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 205.0/276.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 206.0/276.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 206.7/276.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 207.7/276.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 208.5/276.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 209.3/276.6 MB 16.0 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 210.2/276.6 MB 16.4 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 210.9/276.6 MB 16.4 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 211.5/276.6 MB 17.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 212.5/276.6 MB 17.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 213.4/276.6 MB 17.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 214.3/276.6 MB 17.7 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 215.1/276.6 MB 17.7 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 215.9/276.6 MB 17.7 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 216.5/276.6 MB 17.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 217.0/276.6 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 217.8/276.6 MB 16.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 218.5/276.6 MB 16.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 219.4/276.6 MB 16.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 220.0/276.6 MB 16.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 221.1/276.6 MB 16.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 221.8/276.6 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 222.7/276.6 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 223.4/276.6 MB 16.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 224.0/276.6 MB 16.0 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 224.9/276.6 MB 16.0 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 225.6/276.6 MB 16.0 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 226.5/276.6 MB 16.4 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 227.1/276.6 MB 16.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 227.8/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 228.4/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 229.3/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 230.1/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 231.0/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 231.8/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 232.6/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 233.5/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 234.0/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 234.9/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 235.6/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 236.6/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 237.2/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 238.2/276.6 MB 17.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 238.9/276.6 MB 17.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 239.4/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 239.8/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 240.6/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 241.7/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 242.6/276.6 MB 16.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 242.7/276.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 243.9/276.6 MB 16.0 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 244.7/276.6 MB 16.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 245.5/276.6 MB 16.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 246.5/276.6 MB 16.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 247.4/276.6 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 248.3/276.6 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 249.3/276.6 MB 17.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 250.2/276.6 MB 18.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 251.0/276.6 MB 18.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 251.9/276.6 MB 18.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 252.9/276.6 MB 18.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 253.7/276.6 MB 19.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 254.5/276.6 MB 19.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 255.5/276.6 MB 19.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 256.2/276.6 MB 19.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 256.9/276.6 MB 18.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 257.9/276.6 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 258.5/276.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 259.4/276.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 260.2/276.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 261.2/276.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 261.9/276.6 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 262.3/276.6 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 263.4/276.6 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 264.2/276.6 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 265.1/276.6 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 265.9/276.6 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 266.9/276.6 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 267.6/276.6 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 268.2/276.6 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 268.9/276.6 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 269.2/276.6 MB 16.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  269.9/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  270.7/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  271.0/276.6 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  271.9/276.6 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.9/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  273.6/276.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  274.4/276.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  275.3/276.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.2/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 276.6/276.6 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.57.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/4.3 MB 2.2 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.3/4.3 MB 3.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.5/4.3 MB 4.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.9/4.3 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.2/4.3 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.6/4.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.9/4.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.4/4.3 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.8/4.3 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.3/4.3 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.0/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.7 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.7/1.7 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.1/1.7 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.6/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/24.4 MB 7.9 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.4/24.4 MB 6.4 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.9/24.4 MB 7.0 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.2/24.4 MB 7.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.7/24.4 MB 7.8 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.1/24.4 MB 8.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.6/24.4 MB 8.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 3.0/24.4 MB 8.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.6/24.4 MB 8.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.1/24.4 MB 9.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.8/24.4 MB 9.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.8/24.4 MB 9.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.8/24.4 MB 9.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 5.9/24.4 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.1/24.4 MB 8.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 7.1/24.4 MB 9.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.2/24.4 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.0/24.4 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.2/24.4 MB 9.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.8/24.4 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.3/24.4 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 9.9/24.4 MB 9.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.1/24.4 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.6/24.4 MB 10.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.4/24.4 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.4/24.4 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.4/24.4 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 13.9/24.4 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.0/24.4 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 14.8/24.4 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.3/24.4 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.3/24.4 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.8/24.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.8/24.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.8/24.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.9/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.4/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.2/24.4 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.3/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.0/24.4 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.2/24.4 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.1/24.4 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.8/24.4 MB 9.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.3/24.4 MB 9.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.5/24.4 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.4/24.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.7/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.6/24.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.6/24.4 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.7/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.4 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.24.2-cp310-abi3-win_amd64.whl (430 kB)\n",
      "   ---------------------------------------- 0.0/430.4 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 174.1/430.4 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  430.1/430.4 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 430.4/430.4 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "   ---------------------------------------- 0.0/440.8 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 276.5/440.8 kB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  440.3/440.8 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 440.8/440.8 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.8 kB ? eta -:--:--\n",
      "   -------------------------------------- - 174.1/181.8 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 181.8/181.8 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: libclang, flatbuffers, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.57.0 keras-2.13.1 libclang-16.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 typing-extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "#pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74abe13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn . neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f604cc",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e336224e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_centroid_col</th>\n",
       "      <th>region_centroid_row</th>\n",
       "      <th>region_pixel_count</th>\n",
       "      <th>short_line_density_5</th>\n",
       "      <th>short_line_density_2</th>\n",
       "      <th>vedge_mean</th>\n",
       "      <th>vegde_sd</th>\n",
       "      <th>hedge_mean</th>\n",
       "      <th>hedge_sd</th>\n",
       "      <th>intensity_mean</th>\n",
       "      <th>rawred_mean</th>\n",
       "      <th>rawblue_mean</th>\n",
       "      <th>rawgreen_mean</th>\n",
       "      <th>exred_mean</th>\n",
       "      <th>exblue_mean</th>\n",
       "      <th>exgreen_mean</th>\n",
       "      <th>value_mean</th>\n",
       "      <th>saturation_mean</th>\n",
       "      <th>hue_mean</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218</td>\n",
       "      <td>178</td>\n",
       "      <td>9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.54</td>\n",
       "      <td>59.63</td>\n",
       "      <td>52.44</td>\n",
       "      <td>75.22</td>\n",
       "      <td>51.22</td>\n",
       "      <td>-21.56</td>\n",
       "      <td>46.78</td>\n",
       "      <td>-25.22</td>\n",
       "      <td>75.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>foliage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.03</td>\n",
       "      <td>123.04</td>\n",
       "      <td>111.89</td>\n",
       "      <td>139.78</td>\n",
       "      <td>117.44</td>\n",
       "      <td>-33.44</td>\n",
       "      <td>50.22</td>\n",
       "      <td>-16.78</td>\n",
       "      <td>139.78</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>173</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.78</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>43.59</td>\n",
       "      <td>39.56</td>\n",
       "      <td>52.89</td>\n",
       "      <td>38.33</td>\n",
       "      <td>-12.11</td>\n",
       "      <td>27.89</td>\n",
       "      <td>-15.78</td>\n",
       "      <td>52.89</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>197</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.93</td>\n",
       "      <td>49.59</td>\n",
       "      <td>44.22</td>\n",
       "      <td>61.56</td>\n",
       "      <td>43.00</td>\n",
       "      <td>-16.11</td>\n",
       "      <td>35.89</td>\n",
       "      <td>-19.78</td>\n",
       "      <td>61.56</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-2.02</td>\n",
       "      <td>path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>30</td>\n",
       "      <td>102</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.80</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>15.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>14.22</td>\n",
       "      <td>-14.44</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>brickface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>143</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.14</td>\n",
       "      <td>127.63</td>\n",
       "      <td>117.67</td>\n",
       "      <td>141.67</td>\n",
       "      <td>123.56</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>42.11</td>\n",
       "      <td>-12.22</td>\n",
       "      <td>141.67</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.17</td>\n",
       "      <td>59.00</td>\n",
       "      <td>51.33</td>\n",
       "      <td>74.44</td>\n",
       "      <td>51.22</td>\n",
       "      <td>-23.00</td>\n",
       "      <td>46.33</td>\n",
       "      <td>-23.33</td>\n",
       "      <td>74.44</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>cement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>98</td>\n",
       "      <td>133</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>5.44</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>foliage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>19</td>\n",
       "      <td>147</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.89</td>\n",
       "      <td>6.67</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>7.56</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>brickface</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2310 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      region_centroid_col  region_centroid_row  region_pixel_count  \\\n",
       "0                     218                  178                   9   \n",
       "1                     113                  130                   9   \n",
       "2                     202                   41                   9   \n",
       "3                      32                  173                   9   \n",
       "4                      61                  197                   9   \n",
       "...                   ...                  ...                 ...   \n",
       "2305                   30                  102                   9   \n",
       "2306                  143                   24                   9   \n",
       "2307                   80                   72                   9   \n",
       "2308                   98                  133                   9   \n",
       "2309                   19                  147                   9   \n",
       "\n",
       "      short_line_density_5  short_line_density_2  vedge_mean  vegde_sd  \\\n",
       "0                     0.11                   0.0        0.83      0.55   \n",
       "1                     0.00                   0.0        0.28      0.25   \n",
       "2                     0.00                   0.0        0.94      0.77   \n",
       "3                     0.00                   0.0        1.72      1.78   \n",
       "4                     0.00                   0.0        1.44      1.52   \n",
       "...                    ...                   ...         ...       ...   \n",
       "2305                  0.00                   0.0        1.22      0.12   \n",
       "2306                  0.00                   0.0        1.28      0.91   \n",
       "2307                  0.00                   0.0        1.22      1.00   \n",
       "2308                  0.00                   0.0        0.56      0.17   \n",
       "2309                  0.00                   0.0        0.22      0.07   \n",
       "\n",
       "      hedge_mean  hedge_sd  intensity_mean  rawred_mean  rawblue_mean  \\\n",
       "0           1.11      0.54           59.63        52.44         75.22   \n",
       "1           0.33      0.37            0.89         0.00          2.56   \n",
       "2           1.11      1.03          123.04       111.89        139.78   \n",
       "3           9.00      6.75           43.59        39.56         52.89   \n",
       "4           2.61      1.93           49.59        44.22         61.56   \n",
       "...          ...       ...             ...          ...           ...   \n",
       "2305        1.33      0.80           20.26        20.33         25.00   \n",
       "2306        0.89      1.14          127.63       117.67        141.67   \n",
       "2307        1.44      1.17           59.00        51.33         74.44   \n",
       "2308        0.39      0.33            0.96         0.00          2.78   \n",
       "2309        0.50      0.08            4.15         3.89          6.67   \n",
       "\n",
       "      rawgreen_mean  exred_mean  exblue_mean  exgreen_mean  value_mean  \\\n",
       "0             51.22      -21.56        46.78        -25.22       75.22   \n",
       "1              0.11       -2.67         5.00         -2.33        2.56   \n",
       "2            117.44      -33.44        50.22        -16.78      139.78   \n",
       "3             38.33      -12.11        27.89        -15.78       52.89   \n",
       "4             43.00      -16.11        35.89        -19.78       61.56   \n",
       "...             ...         ...          ...           ...         ...   \n",
       "2305          15.44        0.22        14.22        -14.44       25.00   \n",
       "2306         123.56      -29.89        42.11        -12.22      141.67   \n",
       "2307          51.22      -23.00        46.33        -23.33       74.44   \n",
       "2308           0.11       -2.89         5.44         -2.56        2.78   \n",
       "2309           1.89       -0.78         7.56         -6.78        7.00   \n",
       "\n",
       "      saturation_mean  hue_mean     classe  \n",
       "0                0.32     -2.04       path  \n",
       "1                1.00     -2.12    foliage  \n",
       "2                0.20     -2.30        sky  \n",
       "3                0.27     -2.00       path  \n",
       "4                0.30     -2.02       path  \n",
       "...               ...       ...        ...  \n",
       "2305             0.38     -1.56  brickface  \n",
       "2306             0.17     -2.35        sky  \n",
       "2307             0.31     -2.09     cement  \n",
       "2308             1.00     -2.12    foliage  \n",
       "2309             0.71     -1.48  brickface  \n",
       "\n",
       "[2310 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel('segmentation.xlsx')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165736f",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0348474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_centroid_col</th>\n",
       "      <th>region_centroid_row</th>\n",
       "      <th>region_pixel_count</th>\n",
       "      <th>short_line_density_5</th>\n",
       "      <th>short_line_density_2</th>\n",
       "      <th>vedge_mean</th>\n",
       "      <th>vegde_sd</th>\n",
       "      <th>hedge_mean</th>\n",
       "      <th>hedge_sd</th>\n",
       "      <th>intensity_mean</th>\n",
       "      <th>rawred_mean</th>\n",
       "      <th>rawblue_mean</th>\n",
       "      <th>rawgreen_mean</th>\n",
       "      <th>exred_mean</th>\n",
       "      <th>exblue_mean</th>\n",
       "      <th>exgreen_mean</th>\n",
       "      <th>value_mean</th>\n",
       "      <th>saturation_mean</th>\n",
       "      <th>hue_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218</td>\n",
       "      <td>178</td>\n",
       "      <td>9</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.54</td>\n",
       "      <td>59.63</td>\n",
       "      <td>52.44</td>\n",
       "      <td>75.22</td>\n",
       "      <td>51.22</td>\n",
       "      <td>-21.56</td>\n",
       "      <td>46.78</td>\n",
       "      <td>-25.22</td>\n",
       "      <td>75.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.03</td>\n",
       "      <td>123.04</td>\n",
       "      <td>111.89</td>\n",
       "      <td>139.78</td>\n",
       "      <td>117.44</td>\n",
       "      <td>-33.44</td>\n",
       "      <td>50.22</td>\n",
       "      <td>-16.78</td>\n",
       "      <td>139.78</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>173</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.78</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>43.59</td>\n",
       "      <td>39.56</td>\n",
       "      <td>52.89</td>\n",
       "      <td>38.33</td>\n",
       "      <td>-12.11</td>\n",
       "      <td>27.89</td>\n",
       "      <td>-15.78</td>\n",
       "      <td>52.89</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>197</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.93</td>\n",
       "      <td>49.59</td>\n",
       "      <td>44.22</td>\n",
       "      <td>61.56</td>\n",
       "      <td>43.00</td>\n",
       "      <td>-16.11</td>\n",
       "      <td>35.89</td>\n",
       "      <td>-19.78</td>\n",
       "      <td>61.56</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>30</td>\n",
       "      <td>102</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.80</td>\n",
       "      <td>20.26</td>\n",
       "      <td>20.33</td>\n",
       "      <td>25.00</td>\n",
       "      <td>15.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>14.22</td>\n",
       "      <td>-14.44</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>143</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.14</td>\n",
       "      <td>127.63</td>\n",
       "      <td>117.67</td>\n",
       "      <td>141.67</td>\n",
       "      <td>123.56</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>42.11</td>\n",
       "      <td>-12.22</td>\n",
       "      <td>141.67</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.17</td>\n",
       "      <td>59.00</td>\n",
       "      <td>51.33</td>\n",
       "      <td>74.44</td>\n",
       "      <td>51.22</td>\n",
       "      <td>-23.00</td>\n",
       "      <td>46.33</td>\n",
       "      <td>-23.33</td>\n",
       "      <td>74.44</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>98</td>\n",
       "      <td>133</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>5.44</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>19</td>\n",
       "      <td>147</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.89</td>\n",
       "      <td>6.67</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>7.56</td>\n",
       "      <td>-6.78</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-1.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2310 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      region_centroid_col  region_centroid_row  region_pixel_count  \\\n",
       "0                     218                  178                   9   \n",
       "1                     113                  130                   9   \n",
       "2                     202                   41                   9   \n",
       "3                      32                  173                   9   \n",
       "4                      61                  197                   9   \n",
       "...                   ...                  ...                 ...   \n",
       "2305                   30                  102                   9   \n",
       "2306                  143                   24                   9   \n",
       "2307                   80                   72                   9   \n",
       "2308                   98                  133                   9   \n",
       "2309                   19                  147                   9   \n",
       "\n",
       "      short_line_density_5  short_line_density_2  vedge_mean  vegde_sd  \\\n",
       "0                     0.11                   0.0        0.83      0.55   \n",
       "1                     0.00                   0.0        0.28      0.25   \n",
       "2                     0.00                   0.0        0.94      0.77   \n",
       "3                     0.00                   0.0        1.72      1.78   \n",
       "4                     0.00                   0.0        1.44      1.52   \n",
       "...                    ...                   ...         ...       ...   \n",
       "2305                  0.00                   0.0        1.22      0.12   \n",
       "2306                  0.00                   0.0        1.28      0.91   \n",
       "2307                  0.00                   0.0        1.22      1.00   \n",
       "2308                  0.00                   0.0        0.56      0.17   \n",
       "2309                  0.00                   0.0        0.22      0.07   \n",
       "\n",
       "      hedge_mean  hedge_sd  intensity_mean  rawred_mean  rawblue_mean  \\\n",
       "0           1.11      0.54           59.63        52.44         75.22   \n",
       "1           0.33      0.37            0.89         0.00          2.56   \n",
       "2           1.11      1.03          123.04       111.89        139.78   \n",
       "3           9.00      6.75           43.59        39.56         52.89   \n",
       "4           2.61      1.93           49.59        44.22         61.56   \n",
       "...          ...       ...             ...          ...           ...   \n",
       "2305        1.33      0.80           20.26        20.33         25.00   \n",
       "2306        0.89      1.14          127.63       117.67        141.67   \n",
       "2307        1.44      1.17           59.00        51.33         74.44   \n",
       "2308        0.39      0.33            0.96         0.00          2.78   \n",
       "2309        0.50      0.08            4.15         3.89          6.67   \n",
       "\n",
       "      rawgreen_mean  exred_mean  exblue_mean  exgreen_mean  value_mean  \\\n",
       "0             51.22      -21.56        46.78        -25.22       75.22   \n",
       "1              0.11       -2.67         5.00         -2.33        2.56   \n",
       "2            117.44      -33.44        50.22        -16.78      139.78   \n",
       "3             38.33      -12.11        27.89        -15.78       52.89   \n",
       "4             43.00      -16.11        35.89        -19.78       61.56   \n",
       "...             ...         ...          ...           ...         ...   \n",
       "2305          15.44        0.22        14.22        -14.44       25.00   \n",
       "2306         123.56      -29.89        42.11        -12.22      141.67   \n",
       "2307          51.22      -23.00        46.33        -23.33       74.44   \n",
       "2308           0.11       -2.89         5.44         -2.56        2.78   \n",
       "2309           1.89       -0.78         7.56         -6.78        7.00   \n",
       "\n",
       "      saturation_mean  hue_mean  \n",
       "0                0.32     -2.04  \n",
       "1                1.00     -2.12  \n",
       "2                0.20     -2.30  \n",
       "3                0.27     -2.00  \n",
       "4                0.30     -2.02  \n",
       "...               ...       ...  \n",
       "2305             0.38     -1.56  \n",
       "2306             0.17     -2.35  \n",
       "2307             0.31     -2.09  \n",
       "2308             1.00     -2.12  \n",
       "2309             0.71     -1.48  \n",
       "\n",
       "[2310 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.2761887 ,  0.94973634,  0.        , ...,  0.70102145,\n",
       "        -0.46877222, -0.43831817],\n",
       "       [-0.16333606,  0.11453842,  0.        , ..., -0.99219481,\n",
       "         2.51046151, -0.49010061],\n",
       "       [ 1.05683255, -1.43405774,  0.        , ...,  2.20548115,\n",
       "        -0.99451935, -0.6066111 ],\n",
       "       ...,\n",
       "       [-0.61575812, -0.89465908,  0.        , ...,  0.68284489,\n",
       "        -0.51258448, -0.4706822 ],\n",
       "       [-0.36898245,  0.16673829,  0.        , ..., -0.98706809,\n",
       "         2.51046151, -0.49010061],\n",
       "       [-1.45205346,  0.41033768,  0.        , ..., -0.88872825,\n",
       "         1.23990594, -0.0758411 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "dfs = df.iloc[:, :19]\n",
    "display(dfs)\n",
    "\n",
    "sca = StandardScaler()\n",
    "dfS = sca.fit_transform(dfs)\n",
    "display(dfS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6759f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_centroid_col</th>\n",
       "      <th>region_centroid_row</th>\n",
       "      <th>region_pixel_count</th>\n",
       "      <th>short_line_density_5</th>\n",
       "      <th>short_line_density_2</th>\n",
       "      <th>vedge_mean</th>\n",
       "      <th>vegde_sd</th>\n",
       "      <th>hedge_mean</th>\n",
       "      <th>hedge_sd</th>\n",
       "      <th>intensity_mean</th>\n",
       "      <th>rawred_mean</th>\n",
       "      <th>rawblue_mean</th>\n",
       "      <th>rawgreen_mean</th>\n",
       "      <th>exred_mean</th>\n",
       "      <th>exblue_mean</th>\n",
       "      <th>exgreen_mean</th>\n",
       "      <th>value_mean</th>\n",
       "      <th>saturation_mean</th>\n",
       "      <th>hue_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.276189</td>\n",
       "      <td>0.949736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.410668</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.394306</td>\n",
       "      <td>-0.115068</td>\n",
       "      <td>-0.364251</td>\n",
       "      <td>-0.131018</td>\n",
       "      <td>0.591553</td>\n",
       "      <td>0.560068</td>\n",
       "      <td>0.713087</td>\n",
       "      <td>0.469629</td>\n",
       "      <td>-0.765840</td>\n",
       "      <td>1.296593</td>\n",
       "      <td>-1.428854</td>\n",
       "      <td>0.701021</td>\n",
       "      <td>-0.468772</td>\n",
       "      <td>-0.438318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.163336</td>\n",
       "      <td>0.114538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357047</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.598129</td>\n",
       "      <td>-0.121759</td>\n",
       "      <td>-0.580366</td>\n",
       "      <td>-0.133910</td>\n",
       "      <td>-0.947427</td>\n",
       "      <td>-0.936970</td>\n",
       "      <td>-0.956566</td>\n",
       "      <td>-0.936155</td>\n",
       "      <td>0.865280</td>\n",
       "      <td>-0.838569</td>\n",
       "      <td>0.553118</td>\n",
       "      <td>-0.992195</td>\n",
       "      <td>2.510462</td>\n",
       "      <td>-0.490101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.056833</td>\n",
       "      <td>-1.434058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357047</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.353541</td>\n",
       "      <td>-0.110161</td>\n",
       "      <td>-0.364251</td>\n",
       "      <td>-0.122685</td>\n",
       "      <td>2.252887</td>\n",
       "      <td>2.257225</td>\n",
       "      <td>2.196611</td>\n",
       "      <td>2.291015</td>\n",
       "      <td>-1.791659</td>\n",
       "      <td>1.472394</td>\n",
       "      <td>-0.698062</td>\n",
       "      <td>2.205481</td>\n",
       "      <td>-0.994519</td>\n",
       "      <td>-0.606611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.273827</td>\n",
       "      <td>0.862737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357047</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.064484</td>\n",
       "      <td>-0.087635</td>\n",
       "      <td>1.821843</td>\n",
       "      <td>-0.025404</td>\n",
       "      <td>0.171307</td>\n",
       "      <td>0.192374</td>\n",
       "      <td>0.199966</td>\n",
       "      <td>0.115089</td>\n",
       "      <td>0.050152</td>\n",
       "      <td>0.331222</td>\n",
       "      <td>-0.611475</td>\n",
       "      <td>0.180659</td>\n",
       "      <td>-0.687834</td>\n",
       "      <td>-0.412427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.876244</td>\n",
       "      <td>1.280336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357047</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.168248</td>\n",
       "      <td>-0.093434</td>\n",
       "      <td>0.051357</td>\n",
       "      <td>-0.107378</td>\n",
       "      <td>0.328506</td>\n",
       "      <td>0.325406</td>\n",
       "      <td>0.399194</td>\n",
       "      <td>0.243538</td>\n",
       "      <td>-0.295242</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>-0.957822</td>\n",
       "      <td>0.382699</td>\n",
       "      <td>-0.556397</td>\n",
       "      <td>-0.425373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>-1.301246</td>\n",
       "      <td>-0.372660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357047</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.249777</td>\n",
       "      <td>-0.124658</td>\n",
       "      <td>-0.303295</td>\n",
       "      <td>-0.126597</td>\n",
       "      <td>-0.439936</td>\n",
       "      <td>-0.356597</td>\n",
       "      <td>-0.440918</td>\n",
       "      <td>-0.514502</td>\n",
       "      <td>1.114827</td>\n",
       "      <td>-0.367382</td>\n",
       "      <td>-0.495449</td>\n",
       "      <td>-0.469269</td>\n",
       "      <td>-0.205899</td>\n",
       "      <td>-0.127624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>0.247957</td>\n",
       "      <td>-1.729857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357047</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.227542</td>\n",
       "      <td>-0.107039</td>\n",
       "      <td>-0.425206</td>\n",
       "      <td>-0.120814</td>\n",
       "      <td>2.373144</td>\n",
       "      <td>2.422230</td>\n",
       "      <td>2.240041</td>\n",
       "      <td>2.459346</td>\n",
       "      <td>-1.485122</td>\n",
       "      <td>1.057933</td>\n",
       "      <td>-0.303226</td>\n",
       "      <td>2.249524</td>\n",
       "      <td>-1.125956</td>\n",
       "      <td>-0.638975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>-0.615758</td>\n",
       "      <td>-0.894659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357047</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.249777</td>\n",
       "      <td>-0.105031</td>\n",
       "      <td>-0.272817</td>\n",
       "      <td>-0.120304</td>\n",
       "      <td>0.575047</td>\n",
       "      <td>0.528380</td>\n",
       "      <td>0.695164</td>\n",
       "      <td>0.469629</td>\n",
       "      <td>-0.890182</td>\n",
       "      <td>1.273596</td>\n",
       "      <td>-1.265205</td>\n",
       "      <td>0.682845</td>\n",
       "      <td>-0.512584</td>\n",
       "      <td>-0.470682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>-0.368982</td>\n",
       "      <td>0.166738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357047</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.494364</td>\n",
       "      <td>-0.123543</td>\n",
       "      <td>-0.563742</td>\n",
       "      <td>-0.134590</td>\n",
       "      <td>-0.945593</td>\n",
       "      <td>-0.936970</td>\n",
       "      <td>-0.951511</td>\n",
       "      <td>-0.936155</td>\n",
       "      <td>0.846283</td>\n",
       "      <td>-0.816083</td>\n",
       "      <td>0.533203</td>\n",
       "      <td>-0.987068</td>\n",
       "      <td>2.510462</td>\n",
       "      <td>-0.490101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>-1.452053</td>\n",
       "      <td>0.410338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.357047</td>\n",
       "      <td>-0.194552</td>\n",
       "      <td>-0.620364</td>\n",
       "      <td>-0.125773</td>\n",
       "      <td>-0.533264</td>\n",
       "      <td>-0.138842</td>\n",
       "      <td>-0.862016</td>\n",
       "      <td>-0.825920</td>\n",
       "      <td>-0.862123</td>\n",
       "      <td>-0.887196</td>\n",
       "      <td>1.028478</td>\n",
       "      <td>-0.707741</td>\n",
       "      <td>0.167806</td>\n",
       "      <td>-0.888728</td>\n",
       "      <td>1.239906</td>\n",
       "      <td>-0.075841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2310 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      region_centroid_col  region_centroid_row  region_pixel_count  \\\n",
       "0                1.276189             0.949736                 0.0   \n",
       "1               -0.163336             0.114538                 0.0   \n",
       "2                1.056833            -1.434058                 0.0   \n",
       "3               -1.273827             0.862737                 0.0   \n",
       "4               -0.876244             1.280336                 0.0   \n",
       "...                   ...                  ...                 ...   \n",
       "2305            -1.301246            -0.372660                 0.0   \n",
       "2306             0.247957            -1.729857                 0.0   \n",
       "2307            -0.615758            -0.894659                 0.0   \n",
       "2308            -0.368982             0.166738                 0.0   \n",
       "2309            -1.452053             0.410338                 0.0   \n",
       "\n",
       "      short_line_density_5  short_line_density_2  vedge_mean  vegde_sd  \\\n",
       "0                 2.410668             -0.194552   -0.394306 -0.115068   \n",
       "1                -0.357047             -0.194552   -0.598129 -0.121759   \n",
       "2                -0.357047             -0.194552   -0.353541 -0.110161   \n",
       "3                -0.357047             -0.194552   -0.064484 -0.087635   \n",
       "4                -0.357047             -0.194552   -0.168248 -0.093434   \n",
       "...                    ...                   ...         ...       ...   \n",
       "2305             -0.357047             -0.194552   -0.249777 -0.124658   \n",
       "2306             -0.357047             -0.194552   -0.227542 -0.107039   \n",
       "2307             -0.357047             -0.194552   -0.249777 -0.105031   \n",
       "2308             -0.357047             -0.194552   -0.494364 -0.123543   \n",
       "2309             -0.357047             -0.194552   -0.620364 -0.125773   \n",
       "\n",
       "      hedge_mean  hedge_sd  intensity_mean  rawred_mean  rawblue_mean  \\\n",
       "0      -0.364251 -0.131018        0.591553     0.560068      0.713087   \n",
       "1      -0.580366 -0.133910       -0.947427    -0.936970     -0.956566   \n",
       "2      -0.364251 -0.122685        2.252887     2.257225      2.196611   \n",
       "3       1.821843 -0.025404        0.171307     0.192374      0.199966   \n",
       "4       0.051357 -0.107378        0.328506     0.325406      0.399194   \n",
       "...          ...       ...             ...          ...           ...   \n",
       "2305   -0.303295 -0.126597       -0.439936    -0.356597     -0.440918   \n",
       "2306   -0.425206 -0.120814        2.373144     2.422230      2.240041   \n",
       "2307   -0.272817 -0.120304        0.575047     0.528380      0.695164   \n",
       "2308   -0.563742 -0.134590       -0.945593    -0.936970     -0.951511   \n",
       "2309   -0.533264 -0.138842       -0.862016    -0.825920     -0.862123   \n",
       "\n",
       "      rawgreen_mean  exred_mean  exblue_mean  exgreen_mean  value_mean  \\\n",
       "0          0.469629   -0.765840     1.296593     -1.428854    0.701021   \n",
       "1         -0.936155    0.865280    -0.838569      0.553118   -0.992195   \n",
       "2          2.291015   -1.791659     1.472394     -0.698062    2.205481   \n",
       "3          0.115089    0.050152     0.331222     -0.611475    0.180659   \n",
       "4          0.243538   -0.295242     0.740061     -0.957822    0.382699   \n",
       "...             ...         ...          ...           ...         ...   \n",
       "2305      -0.514502    1.114827    -0.367382     -0.495449   -0.469269   \n",
       "2306       2.459346   -1.485122     1.057933     -0.303226    2.249524   \n",
       "2307       0.469629   -0.890182     1.273596     -1.265205    0.682845   \n",
       "2308      -0.936155    0.846283    -0.816083      0.533203   -0.987068   \n",
       "2309      -0.887196    1.028478    -0.707741      0.167806   -0.888728   \n",
       "\n",
       "      saturation_mean  hue_mean  \n",
       "0           -0.468772 -0.438318  \n",
       "1            2.510462 -0.490101  \n",
       "2           -0.994519 -0.606611  \n",
       "3           -0.687834 -0.412427  \n",
       "4           -0.556397 -0.425373  \n",
       "...               ...       ...  \n",
       "2305        -0.205899 -0.127624  \n",
       "2306        -1.125956 -0.638975  \n",
       "2307        -0.512584 -0.470682  \n",
       "2308         2.510462 -0.490101  \n",
       "2309         1.239906 -0.075841  \n",
       "\n",
       "[2310 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfS = pd.DataFrame(dfS, columns = dfs.columns)\n",
    "display(dfS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2b1ee3",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8974f95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['path' 'foliage' 'sky' 'grass' 'brickface' 'cement' 'window']\n"
     ]
    }
   ],
   "source": [
    "classe = df['classe'].unique()\n",
    "print(classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c31fe",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e324562",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dfS, df['classe'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086610d5",
   "metadata": {},
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23344ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echatilion d'entrainement : \n",
      " brickface    244\n",
      "sky          241\n",
      "grass        235\n",
      "path         231\n",
      "cement       227\n",
      "window       220\n",
      "foliage      219\n",
      "Name: classe, dtype: int64\n",
      "\n",
      " echatilion de test : \n",
      " foliage      111\n",
      "window       110\n",
      "cement       103\n",
      "path          99\n",
      "grass         95\n",
      "sky           89\n",
      "brickface     86\n",
      "Name: classe, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"echatilion d'entrainement :\", '\\n', y_train.value_counts() )\n",
    "print('\\n', \"echatilion de test :\", '\\n', y_test.value_counts() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123bac6",
   "metadata": {},
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11423abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron(random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c86ec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1617, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "713994d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d643ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_6804\\1006896255.py\", line 14, in <module>\n      model.fit(X_train, y_train, epochs=10, batch_size=32)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1085, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1179, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 708, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_764]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Compiler le modle\u001b[39;00m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 14\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'Cast_1' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Alexis\\AppData\\Local\\Temp\\ipykernel_6804\\1006896255.py\", line 14, in <module>\n      model.fit(X_train, y_train, epochs=10, batch_size=32)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1085, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py\", line 1179, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\Alexis\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\metrics\\base_metric.py\", line 708, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_1'\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_764]"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Crer un modle squentiel\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(19,)),\n",
    "    layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler le modle\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca246fa",
   "metadata": {},
   "source": [
    "# 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7bf6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      " [[ 84   1   1   0   0   0   0]\n",
      " [ 20  65   2   1   5   3   7]\n",
      " [  0   0 106   0   0   0   5]\n",
      " [  0   0   0  94   1   0   0]\n",
      " [  0   0   0   0  99   0   0]\n",
      " [  0   0   0   0   0  89   0]\n",
      " [  5   4  42   0   1   0  58]]\n",
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   brickface       0.77      0.98      0.86        86\n",
      "      cement       0.93      0.63      0.75       103\n",
      "     foliage       0.70      0.95      0.81       111\n",
      "       grass       0.99      0.99      0.99        95\n",
      "        path       0.93      1.00      0.97        99\n",
      "         sky       0.97      1.00      0.98        89\n",
      "      window       0.83      0.53      0.64       110\n",
      "\n",
      "    accuracy                           0.86       693\n",
      "   macro avg       0.87      0.87      0.86       693\n",
      "weighted avg       0.87      0.86      0.85       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "y_pred = per_clf.predict(X_test)\n",
    "\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matrice de confusion :\\n\", confusion)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Rapport de classification :\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fb73b7",
   "metadata": {},
   "source": [
    "# 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ef9c88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(30, 30), max_iter=1000,\n",
       "              random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(30, 30), max_iter=1000,\n",
       "              random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(30, 30), max_iter=1000,\n",
       "              random_state=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mlp_tanh = MLPClassifier(hidden_layer_sizes=(30, 30), activation='tanh', max_iter=1000, random_state=1)\n",
    "mlp_tanh.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "mlp_sigmoid = MLPClassifier(hidden_layer_sizes=(30, 30), activation='logistic', max_iter=1000, random_state=1)\n",
    "mlp_sigmoid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236c7a9",
   "metadata": {},
   "source": [
    "# 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19ac4220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(30, 30), max_iter=1000, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(30, 30), max_iter=1000, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30), max_iter=1000, random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_relu = MLPClassifier(hidden_layer_sizes=(30, 30), activation='relu', max_iter=1000, random_state=1)\n",
    "mlp_relu.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c74c4b",
   "metadata": {},
   "source": [
    "# 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d37a71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_relu = mlp_relu.predict(X_test)\n",
    "confusion_relu = confusion_matrix(y_test, y_pred_relu)\n",
    "report_relu = classification_report(y_test, y_pred_relu)\n",
    "\n",
    "# Pour le modle tanh\n",
    "y_pred_tanh = mlp_tanh.predict(X_test)\n",
    "confusion_tanh = confusion_matrix(y_test, y_pred_tanh)\n",
    "report_tanh = classification_report(y_test, y_pred_tanh)\n",
    "\n",
    "# Pour le modle sigmoid\n",
    "y_pred_sigmoid = mlp_sigmoid.predict(X_test)\n",
    "confusion_sigmoid = confusion_matrix(y_test, y_pred_sigmoid)\n",
    "report_sigmoid = classification_report(y_test, y_pred_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dd9f221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 86   0   0   0   0   0   0]\n",
      " [  0  96   1   0   0   0   6]\n",
      " [  0   3 103   1   0   0   4]\n",
      " [  0   0   0  94   1   0   0]\n",
      " [  0   0   0   0  99   0   0]\n",
      " [  0   0   0   0   0  89   0]\n",
      " [  0   1  12   0   0   0  97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brickface       1.00      1.00      1.00        86\n",
      "      cement       0.96      0.93      0.95       103\n",
      "     foliage       0.89      0.93      0.91       111\n",
      "       grass       0.99      0.99      0.99        95\n",
      "        path       0.99      1.00      0.99        99\n",
      "         sky       1.00      1.00      1.00        89\n",
      "      window       0.91      0.88      0.89       110\n",
      "\n",
      "    accuracy                           0.96       693\n",
      "   macro avg       0.96      0.96      0.96       693\n",
      "weighted avg       0.96      0.96      0.96       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_sigmoid)\n",
    "print(report_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73a063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
